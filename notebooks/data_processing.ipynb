{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos paquetes, la idea es procesaro los distintos datos diarios que encontramos entre 01-01-2023 y 31-05-2023, para distintos dias de extraccion y temas, distintos paises y comunidades autonomas. \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta base donde están las carpetas de extracciones\n",
    "base_path = r\"C:\\Users\\34645\\Desktop\\projects\\Obj1_GT\\data\\datos_navegador\"\n",
    "\n",
    "# Lista de códigos ISO de los países de interés\n",
    "iso_codes = [\"ES\", \"IT\", \"UK\", \"FR\", \"PT\", \"DE\"]\n",
    "\n",
    "# Diccionario para almacenar la numeración de extracciones por país\n",
    "extraction_numbers_by_country = {}\n",
    "\n",
    "# Listas para almacenar los DataFrames por set de temas\n",
    "dataframes_set1 = []\n",
    "dataframes_set2 = []\n",
    "\n",
    "# Buscar todas las carpetas de extracciones dentro de la ruta base y ordenarlas cronológicamente\n",
    "extraction_folders = sorted(\n",
    "    [os.path.join(base_path, folder) for folder in os.listdir(base_path) if folder.startswith(\"extraccion_\")]\n",
    ")\n",
    "\n",
    "for folder in extraction_folders:\n",
    "    # Extraer la fecha de la carpeta\n",
    "    extraction_date_match = re.search(r\"extraccion_(\\d{2})(\\d{2})(\\d{4})\", folder)\n",
    "    if extraction_date_match:\n",
    "        extraction_date = f\"{extraction_date_match.group(3)}-{extraction_date_match.group(2)}-{extraction_date_match.group(1)}\"\n",
    "    else:\n",
    "        continue  # Si la carpeta no tiene fecha válida, saltarla\n",
    "\n",
    "    # Obtener la lista de archivos CSV dentro de cada carpeta\n",
    "    csv_files = [f for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "\n",
    "        # Determinar si es set1 o set2\n",
    "        if \"set1_temas\" in file:\n",
    "            tema_set = \"set1\"\n",
    "        elif \"set2_temas\" in file:\n",
    "            tema_set = \"set2\"\n",
    "        else:\n",
    "            continue  # Ignorar archivos que no sean de temas\n",
    "\n",
    "        # Extraer el país desde el nombre del archivo (si no hay sufijo, es España)\n",
    "        country_match = re.search(r\"_(\\w{2})\\.csv$\", file)\n",
    "        if country_match:\n",
    "            country_iso = country_match.group(1).upper()  # Extrae el ISO (ejemplo: 'FR', 'DE', 'UK')\n",
    "        else:\n",
    "            country_iso = \"ES\"  # Si no hay sufijo, asumimos España\n",
    "\n",
    "        # **Asignar número de extracción correctamente**\n",
    "        if country_iso not in extraction_numbers_by_country:\n",
    "            # Si el país aparece por primera vez, su extracción es 1\n",
    "            extraction_numbers_by_country[country_iso] = {extraction_date: 1}\n",
    "        else:\n",
    "            # Si el país ya había aparecido antes, contar correctamente las extracciones por fecha\n",
    "            if extraction_date not in extraction_numbers_by_country[country_iso]:\n",
    "                extraction_numbers_by_country[country_iso][extraction_date] = len(extraction_numbers_by_country[country_iso]) + 1\n",
    "\n",
    "        # Obtener el número de extracción correcto para este país en esta fecha\n",
    "        extraction_number = extraction_numbers_by_country[country_iso][extraction_date]\n",
    "\n",
    "        # Intentar cargar el CSV ignorando la primera fila\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, skiprows=1, encoding=\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file_path, skiprows=1, encoding=\"ISO-8859-1\")\n",
    "\n",
    "        # Renombrar la primera columna como \"date\" y convertirla a formato fecha\n",
    "        df.rename(columns={df.columns[0]: \"date\"}, inplace=True)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors='coerce')\n",
    "\n",
    "        # Limpiar los nombres de las columnas eliminando caracteres especiales\n",
    "        df.columns = df.columns.str.replace(r'[^a-zA-Z0-9_áéíóúñÁÉÍÓÚÑ]', '_', regex=True)\n",
    "\n",
    "        # Transformar a formato long (melt)\n",
    "        df_long = df.melt(id_vars=[\"date\"], var_name=\"tema\", value_name=\"volumen_de_busqueda\")\n",
    "\n",
    "        # Agregar las columnas de metadatos\n",
    "        df_long[\"extraccion\"] = extraction_number  # Número de extracción basado en la primera aparición del país\n",
    "        df_long[\"fecha_extraccion\"] = extraction_date\n",
    "        df_long[\"pais_region\"] = country_iso  # Código ISO del país\n",
    "        df_long[\"categoria\"] = \"temas\"\n",
    "        df_long[\"set\"] = tema_set  # Indica si pertenece a set1 o set2\n",
    "\n",
    "        # Guardar en la lista correspondiente\n",
    "        if tema_set == \"set1\":\n",
    "            dataframes_set1.append(df_long)\n",
    "        else:\n",
    "            dataframes_set2.append(df_long)\n",
    "\n",
    "# Unir todos los DataFrames en sus respectivos sets\n",
    "df_set1_temas = pd.concat(dataframes_set1, ignore_index=True) if dataframes_set1 else pd.DataFrame()\n",
    "df_set2_temas = pd.concat(dataframes_set2, ignore_index=True) if dataframes_set2 else pd.DataFrame()\n",
    "\n",
    "# Ordenar por país, fecha y extracción\n",
    "df_set1_temas.sort_values(by=[\"pais_region\", \"date\", \"tema\", \"extraccion\"], inplace=True)\n",
    "df_set2_temas.sort_values(by=[\"pais_region\", \"date\", \"tema\", \"extraccion\"], inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tema</th>\n",
       "      <th>volumen_de_busqueda</th>\n",
       "      <th>extraccion</th>\n",
       "      <th>fecha_extraccion</th>\n",
       "      <th>pais_region</th>\n",
       "      <th>categoria</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Autobús___Alemania_</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>DE</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Autobús___Alemania_</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>DE</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Automóvil___Alemania_</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>DE</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7399</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Automóvil___Alemania_</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>DE</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Google_Maps___Alemania_</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>DE</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>Autobús___Reino_Unido_</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>UK</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>Automóvil___Reino_Unido_</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>UK</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>Google_Maps___Reino_Unido_</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>UK</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10418</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>Taxi___Reino_Unido_</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>UK</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10116</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>Tránsito_vehicular___Reino_Unido_</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>UK</td>\n",
       "      <td>temas</td>\n",
       "      <td>set2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                               tema  volumen_de_busqueda  \\\n",
       "3322  2023-01-01                Autobús___Alemania_                   19   \n",
       "7097  2023-01-01                Autobús___Alemania_                   18   \n",
       "3624  2023-01-01              Automóvil___Alemania_                   75   \n",
       "7399  2023-01-01              Automóvil___Alemania_                   72   \n",
       "3020  2023-01-01            Google_Maps___Alemania_                   23   \n",
       "...          ...                                ...                  ...   \n",
       "10267 2023-05-31             Autobús___Reino_Unido_                   38   \n",
       "10569 2023-05-31           Automóvil___Reino_Unido_                   98   \n",
       "9965  2023-05-31         Google_Maps___Reino_Unido_                   17   \n",
       "10418 2023-05-31                Taxi___Reino_Unido_                    9   \n",
       "10116 2023-05-31  Tránsito_vehicular___Reino_Unido_                    6   \n",
       "\n",
       "       extraccion fecha_extraccion pais_region categoria   set  \n",
       "3322            1       2025-03-17          DE     temas  set2  \n",
       "7097            2       2025-03-18          DE     temas  set2  \n",
       "3624            1       2025-03-17          DE     temas  set2  \n",
       "7399            2       2025-03-18          DE     temas  set2  \n",
       "3020            1       2025-03-17          DE     temas  set2  \n",
       "...           ...              ...         ...       ...   ...  \n",
       "10267           1       2025-03-18          UK     temas  set2  \n",
       "10569           1       2025-03-18          UK     temas  set2  \n",
       "9965            1       2025-03-18          UK     temas  set2  \n",
       "10418           1       2025-03-18          UK     temas  set2  \n",
       "10116           1       2025-03-18          UK     temas  set2  \n",
       "\n",
       "[10570 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_set2_temas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta base donde están las carpetas de extracciones\n",
    "base_path = r\"C:\\Users\\34645\\Desktop\\projects\\Obj1_GT\\data\\datos_navegador\"\n",
    "\n",
    "# Diccionario con los códigos ISO de las comunidades autónomas\n",
    "region_iso_codes = {\n",
    "    \"AR\": \"Aragón\",\n",
    "    \"RI\": \"La Rioja\",\n",
    "    \"EX\": \"Extremadura\",\n",
    "    \"MD\": \"Comunidad de Madrid\",\n",
    "    \"CT\": \"Cataluña\"\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar la numeración de extracciones por región/país\n",
    "extraction_numbers_by_region = {}\n",
    "\n",
    "# Listas para almacenar los DataFrames por set de keywords\n",
    "dataframes_keywords = {f\"set{i}_long\" for i in range(1, 7)}\n",
    "\n",
    "# Buscar todas las carpetas de extracciones dentro de la ruta base y ordenarlas cronológicamente\n",
    "extraction_folders = sorted(\n",
    "    [os.path.join(base_path, folder) for folder in os.listdir(base_path) if folder.startswith(\"extraccion_\")]\n",
    ")\n",
    "\n",
    "for folder in extraction_folders:\n",
    "    # Extraer la fecha de la carpeta\n",
    "    extraction_date_match = re.search(r\"extraccion_(\\d{2})(\\d{2})(\\d{4})\", folder)\n",
    "    if extraction_date_match:\n",
    "        extraction_date = f\"{extraction_date_match.group(3)}-{extraction_date_match.group(2)}-{extraction_date_match.group(1)}\"\n",
    "    else:\n",
    "        continue  # Si la carpeta no tiene fecha válida, saltarla\n",
    "\n",
    "    # Obtener la lista de archivos CSV dentro de cada carpeta\n",
    "    csv_files = [f for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "\n",
    "        # Determinar qué set de keywords es y asegurarse de que coincida con las claves del diccionario\n",
    "        set_match = re.search(r\"(set\\d+)_long\", file)\n",
    "        if set_match:\n",
    "            keyword_set = f\"{set_match.group(1)}_long\"  # Asegurar que coincida con las claves del diccionario\n",
    "        else:\n",
    "            continue  # Ignorar archivos que no sean de keywords\n",
    "\n",
    "        # Extraer la región desde el nombre del archivo (si no hay sufijo, es España total)\n",
    "        region_match = re.search(r\"_(\\w{2})\\.csv$\", file)\n",
    "        if region_match:\n",
    "            region_iso = region_match.group(1).upper()  # Extrae el ISO (ejemplo: 'AR', 'MD', etc.)\n",
    "            region_name = region_iso_codes.get(region_iso, region_iso)  # Convertir código a nombre\n",
    "        else:\n",
    "            region_iso = \"ES\"  # Si no hay sufijo, asumimos España\n",
    "            region_name = \"España\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta base donde están las carpetas de extracciones\n",
    "base_path = r\"C:\\Users\\34645\\Desktop\\projects\\Obj1_GT\\data\\datos_navegador\"\n",
    "\n",
    "# Diccionario con los códigos ISO de las comunidades autónomas\n",
    "region_iso_codes = {\n",
    "    \"AR\": \"Aragón\",\n",
    "    \"RI\": \"La Rioja\",\n",
    "    \"EX\": \"Extremadura\",\n",
    "    \"MD\": \"Comunidad de Madrid\",\n",
    "    \"CT\": \"Cataluña\"\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar la numeración de extracciones por región/país\n",
    "extraction_numbers_by_region = {}\n",
    "\n",
    "# **CORRECCIÓN: Inicializamos correctamente dataframes_keywords como diccionario**\n",
    "dataframes_keywords = {f\"set{i}_long\": [] for i in range(1, 7)}\n",
    "\n",
    "# Buscar todas las carpetas de extracciones dentro de la ruta base y ordenarlas cronológicamente\n",
    "extraction_folders = sorted(\n",
    "    [os.path.join(base_path, folder) for folder in os.listdir(base_path) if folder.startswith(\"extraccion_\")]\n",
    ")\n",
    "\n",
    "for folder in extraction_folders:\n",
    "    # Extraer la fecha de la carpeta\n",
    "    extraction_date_match = re.search(r\"extraccion_(\\d{2})(\\d{2})(\\d{4})\", folder)\n",
    "    if extraction_date_match:\n",
    "        extraction_date = f\"{extraction_date_match.group(3)}-{extraction_date_match.group(2)}-{extraction_date_match.group(1)}\"\n",
    "    else:\n",
    "        continue  # Si la carpeta no tiene fecha válida, saltarla\n",
    "\n",
    "    # Obtener la lista de archivos CSV dentro de cada carpeta\n",
    "    csv_files = [f for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "\n",
    "        # Determinar qué set de keywords es y asegurarse de que coincida con las claves del diccionario\n",
    "        set_match = re.search(r\"(set\\d+)_long\", file)\n",
    "        if set_match:\n",
    "            keyword_set = f\"{set_match.group(1)}_long\"  # Asegurar que coincida con las claves del diccionario\n",
    "        else:\n",
    "            continue  # Ignorar archivos que no sean de keywords\n",
    "\n",
    "        # Extraer la región desde el nombre del archivo (si no hay sufijo, es España total)\n",
    "        region_match = re.search(r\"_(\\w{2})\\.csv$\", file)\n",
    "        if region_match:\n",
    "            region_iso = region_match.group(1).upper()  # Extrae el ISO (ejemplo: 'AR', 'MD', etc.)\n",
    "            region_name = region_iso_codes.get(region_iso, region_iso)  # Convertir código a nombre\n",
    "        else:\n",
    "            region_iso = \"ES\"  # Si no hay sufijo, asumimos España\n",
    "            region_name = \"España\"\n",
    "\n",
    "        # **Asignar número de extracción correctamente**\n",
    "        if region_iso not in extraction_numbers_by_region:\n",
    "            # Si la región aparece por primera vez, su extracción es 1\n",
    "            extraction_numbers_by_region[region_iso] = {extraction_date: 1}\n",
    "        else:\n",
    "            # Si la región ya había aparecido antes, contar correctamente las extracciones por fecha\n",
    "            if extraction_date not in extraction_numbers_by_region[region_iso]:\n",
    "                extraction_numbers_by_region[region_iso][extraction_date] = len(extraction_numbers_by_region[region_iso]) + 1\n",
    "\n",
    "        # Obtener el número de extracción correcto para esta región en esta fecha\n",
    "        extraction_number = extraction_numbers_by_region[region_iso][extraction_date]\n",
    "\n",
    "        # Intentar cargar el CSV ignorando la primera fila\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, skiprows=1, encoding=\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file_path, skiprows=1, encoding=\"ISO-8859-1\")\n",
    "\n",
    "        # Renombrar la primera columna como \"date\" y convertirla a formato fecha\n",
    "        df.rename(columns={df.columns[0]: \"date\"}, inplace=True)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors='coerce')\n",
    "\n",
    "        # Limpiar los nombres de las columnas eliminando caracteres especiales\n",
    "        df.columns = df.columns.str.replace(r'[^a-zA-Z0-9_áéíóúñÁÉÍÓÚÑ]', '_', regex=True)\n",
    "\n",
    "        # Transformar a formato long (melt)\n",
    "        df_long = df.melt(id_vars=[\"date\"], var_name=\"keyword\", value_name=\"volumen_de_busqueda\")\n",
    "\n",
    "        # Agregar las columnas de metadatos\n",
    "        df_long[\"extraccion\"] = extraction_number  # Número de extracción basado en la primera aparición de la región\n",
    "        df_long[\"fecha_extraccion\"] = extraction_date\n",
    "        df_long[\"region\"] = region_iso  # Código ISO de la región\n",
    "        df_long[\"region_nombre\"] = region_name  # Nombre de la región\n",
    "        df_long[\"categoria\"] = \"keywords\"\n",
    "        df_long[\"set\"] = keyword_set  # Indica el set de keywords\n",
    "\n",
    "        # Guardar en la lista correspondiente al set\n",
    "        if keyword_set in dataframes_keywords:  # Verificar que la clave existe en el diccionario\n",
    "            dataframes_keywords[keyword_set].append(df_long)\n",
    "        else:\n",
    "            print(f\"Advertencia: {keyword_set} no encontrado en dataframes_keywords\")\n",
    "\n",
    "# Unir todos los DataFrames en sus respectivos sets\n",
    "df_keywords_sets = {}\n",
    "for key, data in dataframes_keywords.items():\n",
    "    df_keywords_sets[key] = pd.concat(data, ignore_index=True) if data else pd.DataFrame()\n",
    "\n",
    "# Ordenar por región, fecha y extracción\n",
    "for key in df_keywords_sets:\n",
    "    df_keywords_sets[key].sort_values(by=[\"region\", \"date\", \"keyword\", \"extraccion\"], inplace=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytrends",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
